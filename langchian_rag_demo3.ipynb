{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-07T05:03:54.487709Z",
     "start_time": "2026-01-07T05:03:46.618339Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_classic.output_parsers import ResponseSchema\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "# ChatPromptTemplate\n",
    "model = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "\n",
    "# basic_qa_chain = model | StrOutputParser()\n",
    "\n",
    "# response = basic_qa_chain.invoke(\"请自我介绍。\")\n",
    "# print(response)\n",
    "\n",
    "# 解析布尔输出\n",
    "from langchain_classic.output_parsers.boolean import BooleanOutputParser\n",
    "# BooleanOutputParser\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"你是一个乐于助人的帮手，请根据用户的问题给出回答。\"),\n",
    "    (\"user\", \"这是用户的问题：{topic}\")\n",
    "])\n",
    "\n",
    "math_qa_chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "question1 = \\\n",
    "\"\"\"\n",
    "Alice and Bob are each holding some integer number of sweets. Alice says to Bob: “If\n",
    "we each added the number of sweets we’re holding to our (positive integer) age, my answer would\n",
    "be double yours. If we took the product, then my answer would be four times yours.” Bob replies:\n",
    "“Why don’t you give me five of your sweets because then both our sum and product would be equal.”\n",
    "What is the product of Alice and Bob’s ages?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "question = \\\n",
    "\"\"\"\n",
    "what is 1 / 0?\n",
    "\"\"\"\n",
    "\n",
    "result = math_qa_chain.invoke({\"topic\": question})\n",
    "\n",
    "print(result)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是一个很好的数学问题！  \n",
      "\n",
      "1 除以 0 在数学中**没有定义**，也就是说它没有意义。原因如下：  \n",
      "\n",
      "- 除法可以理解为“一个数乘以多少等于另一个数”。  \n",
      "  比如 \\( 1 / 0 = x \\) 意味着 \\( 0 \\times x = 1 \\)，但任何数乘以 0 都等于 0，不可能等于 1，所以这样的 \\( x \\) 不存在。  \n",
      "\n",
      "- 从极限的角度看，如果让除数越来越接近 0，比如 \\( 1 / 0.1 = 10 \\)，\\( 1 / 0.01 = 100 \\)，\\( 1 / 0.001 = 1000 \\)……结果会趋向无穷大，但无穷大不是一个确定的实数，而且从负方向接近 0 会趋向负无穷，所以极限也不唯一。  \n",
      "\n",
      "因此，在标准算术中，**除以零是未定义的**。\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:36:45.567116Z",
     "start_time": "2026-01-08T09:36:43.805431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"name\", description=\"用户的姓名\"),\n",
    "    ResponseSchema(name=\"age\", description=\"用户的年龄\")\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"请根据以下内容提取用户信息，并返回 JSON 格式：\\n{input}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "format_instructions = parser.get_format_instructions()\n",
    "print(format_instructions)\n",
    "\n",
    "chain = (\n",
    "    prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"input\": \"用户叫李雷，今年25岁，是一名工程师。\"})\n",
    "\n",
    "print(result)"
   ],
   "id": "cc74a47d65491b18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"name\": string  // 用户的姓名\n",
      "\t\"age\": string  // 用户的年龄\n",
      "}\n",
      "```\n",
      "{'name': '李雷', 'age': '25'}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "LECL -- LangChainExpressionLanguage\n",
    "函数式管道风格，允许通过管道符连接两个元素，实现功能的串联\n",
    "invoke\n",
    "stream\n",
    "batch"
   ],
   "id": "1b807ae0c57b7dd8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T09:16:37.874807Z",
     "start_time": "2026-01-09T09:16:26.338791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# 构建复合链\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence, RunnableLambda\n",
    "from langchain_classic.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "\n",
    "news_gen_prompt = PromptTemplate.from_template(\n",
    "    \"请根据以下新闻标题撰写一则简短的新闻内容，100字以内：\\n\\n{title}\"\n",
    ")\n",
    "\n",
    "# model输出一个AIMessage\n",
    "news_chain = news_gen_prompt | model\n",
    "\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"time\", description=\"事件发生的时间\"),\n",
    "    ResponseSchema(name=\"location\", description=\"事件发生的地点\"),\n",
    "    ResponseSchema(name=\"event\", description=\"发生的具体事件\")\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"请从下面的新闻内容中提取关键信息，并返回结构化的json格式：\\n\\n{news}\\n\\n{format_instructions}\"\n",
    ")\n",
    "\n",
    "summary_chain = (\n",
    "    summary_prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "combined_chain = news_chain | summary_chain\n",
    "\n",
    "response = combined_chain.invoke({\"title\": \"陨石撞击地球\"})\n",
    "\n",
    "print(response)\n"
   ],
   "id": "428d52718a9f2a3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': '昨日凌晨', 'location': '太平洋无人海域', 'event': '一颗直径约10米的陨石坠入，未造成人员伤亡及财产损失，相关机构正对陨石碎片展开研究'}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T04:14:30.054372Z",
     "start_time": "2026-01-12T04:14:16.313306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "chatbot_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"你叫小智，是一名乐于助人的助手。\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "basic_qa_chain = chatbot_prompt | model | StrOutputParser()\n",
    "messages_list = [\n",
    "    HumanMessage(content=\"你好，我叫程明，好久不见。\"),\n",
    "    AIMessage(content=\"你好呀！我叫小智，是一名乐于助人的ai助手，很高兴认识你。\")\n",
    "]\n",
    "\n",
    "question = \"你好，请详细介绍一下你自己。\"\n",
    "messages_list.append(HumanMessage(content=question))\n",
    "# result = basic_qa_chain.invoke({\"messages\": messages_list})\n",
    "\n",
    "async for chunk in basic_qa_chain.astream({\"messages\": messages_list}):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "# print(result)"
   ],
   "id": "d75609539ae2d00a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是小智，一个由深度求索公司开发的AI助手。很高兴能为你详细介绍我自己：\n",
      "\n",
      "**我的能力：**\n",
      "- 知识问答：涵盖科学、历史、文化、生活等各个领域\n",
      "- 文本处理：写作、翻译、总结、改写等\n",
      "- 逻辑推理：数学计算、问题分析、方案建议\n",
      "- 创意生成：故事创作、诗歌写作、头脑风暴\n",
      "- 编程帮助：代码解释、调试建议、算法思路\n",
      "\n",
      "**我的特点：**\n",
      "- 完全免费使用\n",
      "- 支持128K长上下文对话\n",
      "- 会主动承认知识盲区\n",
      "- 注重回答的准确性和安全性\n",
      "\n",
      "**我的限制：**\n",
      "- 知识截止到2024年7月\n",
      "- 无法处理实时信息\n",
      "- 没有个人情感和主观体验\n",
      "\n",
      "有什么具体想了解的吗？或者想试试我的什么功能？😊"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from langchain_text_splitters import RecursiveCharacterTextSplitter",
   "id": "66e09b82632e8ca5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Langchain 接入工具\n",
    "\n",
    "- 基本流程\n",
    "\n",
    "    - MCP\n",
    "    - LangChain 内置工具\n"
   ],
   "id": "f918afbd935d885"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T08:11:00.618884Z",
     "start_time": "2026-01-14T08:10:58.782261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_experimental.tools import PythonAstREPLTool # Python交互式解释环境，能够保存运行上下文\n",
    "\n",
    "\n",
    "# 电信用户流失预测\n",
    "path = \"/mnt/d/aistudy/dataset/langchain/telco/Telco_customer_churn.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "# df.head(5)\n",
    "tool = PythonAstREPLTool(locals={\"df\": df})\n",
    "# tool.invoke(\"df.columns\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "\n",
    "llm_with_tool = model.bind_tools([tool])\n",
    "\n",
    "# response = llm_with_tool.invoke(\n",
    "#     \"我有一张表名为df，请告诉我表的列名\"\n",
    "# )\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputKeyToolsParser\n",
    "parser = JsonOutputKeyToolsParser(\n",
    "    key_name=tool.name,\n",
    "    first_tool_only=True\n",
    ")\n",
    "chain = llm_with_tool | parser\n",
    "# response = chain.invoke(\"我有一张表名为df，请告诉我表的列名\")\n",
    "\n",
    "system_prompt = \\\n",
    "\"\"\"\n",
    "你可以访问一个名为'df'的pandas数据框，你可以使用df.head().to_markdown()查看数据集的基本信息。\n",
    "请根据用户提出的问题，编写Python代码来混搭，只返回代码，不返回其他内容。只允许使用pandas和内置库。\n",
    "\"\"\"\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "def _extract_code(message):\n",
    "    return message[\"query\"]\n",
    "\n",
    "extract_code = RunnableLambda(_extract_code)\n",
    "chain = prompt | llm_with_tool | parser | extract_code | tool\n",
    "# chain = prompt\n",
    "response = chain.invoke({\"question\": \"统计已流失的用户有多少人？\"})\n",
    "response"
   ],
   "id": "48b77f5ba873418f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content=\"\\n你可以访问一个名为'df'的pandas数据框，你可以使用df.head().to_markdown()查看数据集的基本信息。\\n请根据用户提出的问题，编写Python代码来混搭，只返回代码，不返回其他内容。只允许使用pandas和内置库。\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='统计已流失的用户有多少人？', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T07:51:59.331140Z",
     "start_time": "2026-01-17T07:51:56.522003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import os\n",
    "# https://api.openweathermap.org/data/2.5/weather?q={city name}&appid={API key}\n",
    "\n",
    "@tool\n",
    "def get_weather(city):\n",
    "    \"\"\"\n",
    "    获取指定城市当前的天气情况\n",
    "    :param city: 必要参数，城市名，应当为英文形式\n",
    "    :return: 接口响应，json格式\n",
    "    \"\"\"\n",
    "    url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\n",
    "        \"q\": city,\n",
    "        \"appid\": os.getenv(\"OWM_APPID\"),\n",
    "        \"units\": \"metric\",\n",
    "        \"lang\": \"zh_cn\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "print(get_weather.name)\n",
    "print(get_weather.description)\n",
    "print(get_weather.args)\n",
    "\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "chat_model = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "chat_model = chat_model.bind_tools([get_weather])\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputKeyToolsParser\n",
    "parser = JsonOutputKeyToolsParser(key_name=get_weather.name, first_tool_only=True)\n",
    "\n",
    "chain = chat_model # | parser # | get_weather\n",
    "\n",
    "# response = chain.invoke(\"请问北京天气怎么样？\")\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "你将收到一段 JSON 格式的天气数据，请用简洁自然的方式将其转述给用户。\n",
    "以下是天气 JSON 数据：\n",
    "\n",
    "```json\n",
    "{weather_json}\n",
    "```\n",
    "\n",
    "请将其转换为中文天气描述，例如：\n",
    "“北京当前天气晴，气温为23℃，湿度58%，风速2.1米/秒。”\n",
    "只返回一句话描述，不要其他说明或解释。\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "output_chain = output_prompt | chat_model | StrOutputParser()\n",
    "\n",
    "# weather_json = chain.invoke(\"请问成都天气怎么样？\")\n",
    "#\n",
    "# response = output_chain.invoke({\"weather_json\": weather_json})\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "combined_chain = chain # | RunnableLambda(lambda x: {\"weather_json\": x}) | output_chain\n",
    "response = combined_chain.invoke(\"请问华盛顿的天气怎么样？\")\n",
    "print(response)"
   ],
   "id": "33b0cf1b2299a836",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_weather\n",
      "获取指定城市当前的天气情况\n",
      ":param city: 必要参数，城市名，应当为英文形式\n",
      ":return: 接口响应，json格式\n",
      "{'city': {'title': 'City'}}\n",
      "content='我需要确认一下您指的是哪个华盛顿。美国有两个主要的地方都叫华盛顿：\\n\\n1. **华盛顿州**（Washington State）- 美国西北部的一个州\\n2. **华盛顿特区**（Washington D.C.）- 美国的首都\\n\\n您想知道的是哪个地方的天气呢？' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 325, 'total_tokens': 382, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 320}, 'prompt_cache_hit_tokens': 320, 'prompt_cache_miss_tokens': 5}, 'model_provider': 'deepseek', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': '0fbea8ab-831d-4e36-bed8-72bc98c3dabc', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bcaf0-7b9b-7071-8d6f-50bcffb7a88e-0' usage_metadata={'input_tokens': 325, 'output_tokens': 57, 'total_tokens': 382, 'input_token_details': {'cache_read': 320}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T07:42:01.747968Z",
     "start_time": "2026-01-17T07:41:52.527751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_classic.agents import create_tool_calling_agent, tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import requests\n",
    "\n",
    "@tool\n",
    "def get_weather(city):\n",
    "    \"\"\"\n",
    "    获取指定城市当前的天气情况\n",
    "    :param city: 必要参数，城市名，应当为英文形式\n",
    "    :return: 接口响应，json格式\n",
    "    \"\"\"\n",
    "    url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\n",
    "        \"q\": city,\n",
    "        \"appid\": os.getenv(\"OWM_APPID\"),\n",
    "        \"units\": \"metric\",\n",
    "        \"lang\": \"zh_cn\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "tools = [get_weather]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是天气助手，请根据用户的问题，给出相应的天气信息\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])\n",
    "\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "\n",
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "\n",
    "from langchain_classic.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "response = agent_executor.invoke({\"input\": \"请问华盛顿今天的天气怎么样？\"})\n",
    "print(response)\n"
   ],
   "id": "bcfe8b0fcd44ae3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `get_weather` with `{'city': 'Washington'}`\n",
      "responded: 我来帮您查询华盛顿今天的天气情况。\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m{'coord': {'lon': -120.5015, 'lat': 47.5001}, 'weather': [{'id': 800, 'main': 'Clear', 'description': '晴', 'icon': '01n'}], 'base': 'stations', 'main': {'temp': -2.13, 'feels_like': -3.92, 'temp_min': -2.78, 'temp_max': -1.64, 'pressure': 1035, 'humidity': 94, 'sea_level': 1035, 'grnd_level': 947}, 'visibility': 10000, 'wind': {'speed': 1.35, 'deg': 282, 'gust': 1.21}, 'clouds': {'all': 8}, 'dt': 1768635602, 'sys': {'type': 2, 'id': 2003593, 'country': 'US', 'sunrise': 1768578257, 'sunset': 1768610335}, 'timezone': -28800, 'id': 5815135, 'name': 'Washington', 'cod': 200}\u001B[0m\u001B[32;1m\u001B[1;3m根据查询结果，华盛顿（美国）今天的天气情况如下：\n",
      "\n",
      "**天气状况：** 晴朗 ☀️\n",
      "**温度：** -2.13°C（体感温度 -3.92°C）\n",
      "**温度范围：** -2.78°C 到 -1.64°C\n",
      "**湿度：** 94%\n",
      "**气压：** 1035 hPa\n",
      "**风速：** 1.35 m/s（约5公里/小时）\n",
      "**风向：** 282度（西风）\n",
      "**能见度：** 10公里\n",
      "**云量：** 8%\n",
      "\n",
      "**总结：** 今天华盛顿天气非常晴朗，但气温较低，在零下2度左右，体感温度更低。湿度较高，风速较小。建议外出时注意保暖，穿着厚实的冬装。\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'input': '请问华盛顿今天的天气怎么样？', 'output': '根据查询结果，华盛顿（美国）今天的天气情况如下：\\n\\n**天气状况：** 晴朗 ☀️\\n**温度：** -2.13°C（体感温度 -3.92°C）\\n**温度范围：** -2.78°C 到 -1.64°C\\n**湿度：** 94%\\n**气压：** 1035 hPa\\n**风速：** 1.35 m/s（约5公里/小时）\\n**风向：** 282度（西风）\\n**能见度：** 10公里\\n**云量：** 8%\\n\\n**总结：** 今天华盛顿天气非常晴朗，但气温较低，在零下2度左右，体感温度更低。湿度较高，风速较小。建议外出时注意保暖，穿着厚实的冬装。'}\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
